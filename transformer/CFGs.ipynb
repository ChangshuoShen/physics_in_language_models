{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CFG\n",
    "提出问题：是否存在一种让我们理解语言模型如何完成复杂任务（涉及深层逻辑/推理/计算链）的设置？\n",
    "* 建议使用上下文无关语法（CFG）合成语言\n",
    "* CFG包括终端符号T，非终端符号NT，根符号以及产生规则，可以层次化地产生高度结构化的表达式\n",
    "\n",
    "文中的规则\n",
    "![rules](./learn_CFGs/rules.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31112112132233322322121322331311311331331311333322133332213332211322331311111912132111213211312331133133111718\n",
      "1732121322113212131232233133111183211322331311123311211212112111322321122132113313313111131118\n",
      "1132211123312111321112122112117181919\n",
      "18171919\n",
      "1711221311121212211213331112133121322121113111233118193221111323331231133111331331111121718\n",
      "121331333223113113331211333313313313113221132211221323223322117191817\n",
      "173311212131233333121213121112123313233321832211113221131211221322112213331131133312113123331233322113223121718\n",
      "121211121323223111233121312312121323111213311311121312322111217181919\n",
      "173121133311331111132221123311233132211121123313312122211212211819171212111111233112111111233133111\n",
      "1733112111213223121132211221221311311111919\n",
      "1122133321132333222213332113232231111111132211311331111213217191817\n",
      "332211213322112131131133312121111171917311333333331113121133131111322121322\n",
      "173311212132233111133112111213223331218113311233121322121221312113221212331331331718\n",
      "312121121121331123311333113332322181919\n",
      "18171919\n",
      "1132323312121312221112213313312131133131131112117181919\n",
      "18171919\n",
      "173113312132212132222112133123311118193113111213322131231112113313312111221123311231112133322221312333221718\n",
      "331233133111113231211312121231133113333112112121211322121121213319171233333121122111121132231231211322\n",
      "31112113233312121121112132211111719312121121121212123113311132233312113221718\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class CFG:\n",
    "    def __init__(self, rules, start_symbol):\n",
    "        self.rules = rules\n",
    "        self.start_symbol = start_symbol\n",
    "\n",
    "    def generate(self, symbol=None):\n",
    "        # 没有就直接从root开始\n",
    "        if symbol is None:\n",
    "            symbol = self.start_symbol\n",
    "        # 如果当前symbol不在我们的rules.keys中，那便到了结尾\n",
    "        if symbol not in self.rules:\n",
    "            return symbol\n",
    "        else:\n",
    "            # 这里是正常的，就是按照生成规则随机产生一个\n",
    "            rule = random.choice(self.rules[symbol])\n",
    "            return ''.join(self.generate(sym) for sym in rule)\n",
    "    \n",
    "# 提取的生成规则\n",
    "rules = {\n",
    "    'root': [['20', '21'], ['20', '19', '21'], ['21', '19', '19']],\n",
    "    '20': [['16', '16'], ['16', '17'], ['17', '16', '18']],\n",
    "    '21': [['18', '17'], ['17', '16'], ['16', '17', '18'], ['16', '18']],\n",
    "    '16': [['15', '15'], ['13', '15', '13'], ['14', '13'], ['14', '14']],\n",
    "    '15': [['10', '11', '11'], ['11', '11', '10'], ['10', '10'], ['12', '12', '11']],\n",
    "    '14': [['10', '12'], ['12', '10', '12'], ['12', '11'], ['10', '12', '12']],\n",
    "    '13': [['11', '12'], ['12', '11', '12'], ['10', '12', '11']],\n",
    "    '12': [['7', '9', '7'], ['9', '8'], ['8', '8', '9']],\n",
    "    '11': [['8', '8'], ['9', '7'], ['9', '7', '7']],\n",
    "    '10': [['8', '9', '9'], ['9', '7', '9'], ['7', '9', '9']],\n",
    "    '9': [['1', '2', '1'], ['3', '3'], ['1', '1']],\n",
    "    '8': [['3', '1', '1'], ['1', '2'], ['3', '3', '1']],\n",
    "    '7': [['2', '2', '1'], ['3', '2', '2'], ['3', '1', '2'], ['3', '2']]\n",
    "}\n",
    "\n",
    "cfg = CFG(rules, 'root')\n",
    "\n",
    "# 生成句子\n",
    "for _ in range(20):\n",
    "    print(cfg.generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d439089301a1403d80dc57049ca332f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2SdpaAttention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "# Define GPT-2 configuration\n",
    "gpt2_config = GPT2Config(\n",
    "    n_layer=12,         # Number of layers\n",
    "    n_head=12,          # Number of attention heads\n",
    "    n_embd=768          # Hidden dimensions\n",
    ")\n",
    "\n",
    "# Initialize GPT-2 model\n",
    "gpt2_model = GPT2LMHeadModel(gpt2_config)\n",
    "\n",
    "# Print model summary\n",
    "print(gpt2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaModel(\n",
      "  (embeddings): DebertaEmbeddings(\n",
      "    (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
      "    (position_embeddings): Embedding(512, 768)\n",
      "    (LayerNorm): DebertaLayerNorm()\n",
      "    (dropout): StableDropout()\n",
      "  )\n",
      "  (encoder): DebertaEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x DebertaLayer(\n",
      "        (attention): DebertaAttention(\n",
      "          (self): DisentangledSelfAttention(\n",
      "            (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "          (output): DebertaSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (intermediate): DebertaIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): DebertaOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (LayerNorm): DebertaLayerNorm()\n",
      "          (dropout): StableDropout()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import DebertaConfig, DebertaModel\n",
    "\n",
    "# Define DeBERTa configuration\n",
    "deberta_config = DebertaConfig(\n",
    "    hidden_size=768,    # Hidden dimensions\n",
    "    num_attention_heads=12,  # Number of attention heads\n",
    "    num_hidden_layers=12     # Number of layers\n",
    ")\n",
    "\n",
    "# Initialize DeBERTa model\n",
    "deberta_model = DebertaModel(deberta_config)\n",
    "\n",
    "# Print model summary\n",
    "print(deberta_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
